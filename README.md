![loqa_social_preview_padded_1280x640](https://github.com/user-attachments/assets/99016e57-ace5-4140-a4f3-c49262f83253)
# Loqa â€“ A Local-First Voice Assistant

**Loqa** (formerly *Rosey*) is a privacy-first, local-only voice assistant that operates entirely offline. It enables natural language interaction without relying on cloud infrastructure, commercial APIs, or internet connectivityâ€”designed from the ground up to be private, modular, and extensible.

---

## ğŸ§± System Architecture

### ğŸ–¥ï¸ Loqa Hub (Server)
A single backend node responsible for all heavy processing:

- **Hardware:** Mini PC (e.g. Beelink SER5) running Rust-based Axum server
- **Responsibilities:**
  - Accepts wake word events from pucks
  - Handles STT (via Whisper or similar)
  - Performs intent parsing and command chaining
  - Generates TTS responses (via Coqui or Silero)
  - Streams audio response back to puck

### ğŸ™ï¸ Loqa Lite (Puck)
Multiple embedded clients placed in rooms throughout the home:

- **Hardware:** ESP32-S3-based puck + microphone array
- **Responsibilities:**
  - Local wake word detection (Edge Impulse)
  - Record audio on trigger and forward to Loqa Prime
  - Playback audio response from the server
  - Designed for near-room-scale voice capture

---

## ğŸ”„ Communication Flow

```text
[ Loqa Lite ]
 â””â”€> Wake word detected locally
 â””â”€> Record request audio
 â””â”€> Transmit to Loqa Prime via Wi-Fi

[ Loqa Prime ]
 â””â”€> Convert speech to text
 â””â”€> Parse intent and execute command chain
 â””â”€> Generate audio response
 â””â”€> Send audio back to Loqa Lite for playback
```

---

## ğŸŒ± Future Plans

- Support for **NSL (Neuro-Symbolic Learning)** to allow Loqa to learn new skills from voice interactions
- Multi-room context awareness
- Embedded user identification (voice fingerprinting)
- Offline skill scripting from natural language
- Optional local app for configuration and debugging

---

## ğŸ“¦ Project Structure

```bash
loqa/
â”œâ”€â”€ loqa-hub/           # Rust-based server (Axum, STT, NLP, TTS)
â”œâ”€â”€ puck-fw/            # ESP32 puck firmware (PlatformIO + C++)
â”œâ”€â”€ models/             # Edge Impulse wake word models
â”œâ”€â”€ docs/               # Diagrams, planning notes
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

- **Rust** (Axum web framework)
- **ESP32-S3** (PlatformIO + ESP-IDF)
- **Edge Impulse** (wake word inference)
- **Whisper.cpp / Coqui TTS** (offline STT/TTS)
- **Rodio / ALSA** (audio output)
- **HTTP / TCP** (communication)
- **Optional LLM module** (future experimentation)

---

## ğŸ“œ License

TBD â€” likely MIT or Apache 2.0

---

*Created by [Anna Barnes](https://www.linkedin.com/in/annabethbarnes) to bring voice assistance back to the edgeâ€”where it belongs.*

